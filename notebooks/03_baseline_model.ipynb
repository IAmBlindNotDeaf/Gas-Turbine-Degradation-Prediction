{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c11be829",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importieren der benötigten Bibliotheken\n",
    "\n",
    "# Datenmanipulation\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Visualisierung\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Machine Learning\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.base import clone\n",
    "from sklearn.metrics import root_mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "\n",
    "# Warnings unterdrücken\n",
    "import warnings\n",
    "from sklearn.exceptions import DataConversionWarning\n",
    "warnings.filterwarnings(action=\"ignore\", category=DataConversionWarning)\n",
    "warnings.filterwarnings(action=\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fa25625",
   "metadata": {},
   "source": [
    "# Baseline Modellierung\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "555d93b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Einlesen der Trainings- und Testdaten\n",
    "destination_path = \"../data/processed\"\n",
    "\n",
    "features_train = pd.read_csv(f\"{destination_path}/features_train.csv\")\n",
    "features_test = pd.read_csv(f\"{destination_path}/features_test.csv\")\n",
    "target_train = pd.read_csv(f\"{destination_path}/target_train.csv\")\n",
    "target_test = pd.read_csv(f\"{destination_path}/target_test.csv\")\n",
    "\n",
    "# Zielvariable in einem dict organisieren\n",
    "targets = {\n",
    "    \"compressor\": {\n",
    "        \"train\": target_train.iloc[:, 0],\n",
    "        \"test\": target_test.iloc[:, 0]\n",
    "    },\n",
    "    \"turbine\": {\n",
    "        \"train\": target_train.iloc[:, 1],\n",
    "        \"test\": target_test.iloc[:, 1]\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e90b802",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline-Modelle\n",
    "models = {\n",
    "    \"Linear Regression\": Pipeline([(\"scaler\", StandardScaler()), (\"pca\", PCA(n_components=14)), (\"model\", LinearRegression())]),\n",
    "    \"K-Neighbors\": Pipeline([(\"scaler\", StandardScaler()), (\"pca\", PCA(n_components=14)), (\"model\", KNeighborsRegressor(n_neighbors=5))]),\n",
    "    \"Random Forest\": Pipeline([(\"model\", RandomForestRegressor(random_state=42))]),\n",
    "    \"Decision Tree\": Pipeline([(\"model\", DecisionTreeRegressor(random_state=42))])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab00d14c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluierung der Baseline-Modelle mit allen Features\n",
    "all_results = []\n",
    "\n",
    "# Schleife für Kompressor und Turbine\n",
    "for target_name, target_data in targets.items():\n",
    "    # Split der Zielvariable in Trainings- und Testdaten\n",
    "    target_train_data = target_data[\"train\"]\n",
    "    target_test_data = target_data[\"test\"]\n",
    "    \n",
    "    # Schleife über alle Modelle\n",
    "    for model_name, model_pipeline in models.items():\n",
    "        current_model = clone(model_pipeline) # Klonen des Modells\n",
    "        current_model.fit(features_train, target_train_data) # Training des Modells\n",
    "        target_pred = current_model.predict(features_test) # Vorhersage auf den Testdaten\n",
    "        \n",
    "        # Berechnung der Metriken\n",
    "        r2 = r2_score(target_test_data, target_pred)\n",
    "        mae = mean_absolute_error(target_test_data, target_pred)\n",
    "        rmse = root_mean_squared_error(target_test_data, target_pred)\n",
    "        \n",
    "        # Speichern der Ergebnisse\n",
    "        results = {\"Target\": target_name, \"Model\": model_name, \"R2\": r2, \"MAE\": mae, \"RMSE\": rmse}\n",
    "        all_results.append(results)\n",
    "\n",
    "# Speichern der Ergebnisse in einer CSV-Datei\n",
    "results_df = pd.DataFrame(all_results)\n",
    "results_df.to_csv(\"../data/results/baseline_results.csv\", index=False)\n",
    "\n",
    "print(\"Baseline Modellergebnisse\")\n",
    "print(results_df.round(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eb6c660",
   "metadata": {},
   "source": [
    "# Model Interpretation (Feature Importance)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f048a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trainiere für jedes Target ein RandomForest-Modell mit allen Features\n",
    "feature_names = features_train.columns\n",
    "importance_dfs = {}\n",
    "\n",
    "# Schleife für Kompressor und Turbine\n",
    "for target_name, target_data in targets.items():\n",
    "    rf_model = RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1) # Initialisiere das Modell\n",
    "    rf_model.fit(features_train, target_data['train']) # Trainiere das Modell\n",
    "    \n",
    "    # Extrahiere die Feature Importances\n",
    "    importances = rf_model.feature_importances_\n",
    "    importance_df = pd.DataFrame({\"Feature\": feature_names, \"Importance\": importances})\n",
    "    importance_dfs[target_name] = importance_df.sort_values(by=\"Importance\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f27ac165",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisierung der Feature-Wichtigkeiten\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 8))\n",
    "\n",
    "colors = [\"#009292\"] + [\"#074650\"] * 9\n",
    "\n",
    "# Plot für Kompressor\n",
    "comp_data = importance_dfs[\"compressor\"].head(10).copy()\n",
    "comp_colors = colors[:len(comp_data)]\n",
    "sns.barplot(x=\"Importance\", y=\"Feature\", data=comp_data, ax=axes[0], palette=comp_colors)\n",
    "axes[0].set_title(\"Top 10 Feature-Importance - Kompressor\")\n",
    "\n",
    "# Plot für Turbine\n",
    "turb_data = importance_dfs[\"turbine\"].head(10).copy()\n",
    "turb_colors = colors[:len(turb_data)]\n",
    "sns.barplot(x=\"Importance\", y=\"Feature\", data=turb_data, ax=axes[1], palette=turb_colors)\n",
    "axes[1].set_title(\"Top 10 Feature-Importance - Turbine\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Erstelle \"results\" Verzeichnis\n",
    "os.makedirs(\"../data/results\", exist_ok=True)\n",
    "\n",
    "# Save Top 10 feature importances\n",
    "for target_name, importance_df in importance_dfs.items():\n",
    "    importance_df.head(10).to_csv(f\"../data/results/top_10_feature_importances_{target_name}.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
