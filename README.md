# Vorhersage der Degradation von Gasturbinen in Schiffsantrieben

> Dieses Projekt nutzt Machine-Learning-Regressionsmodelle, um den VerschleiÃŸ (Degradation) der Gasturbine und des Kompressors eines Schiffsantriebs auf Basis von Betriebssensordaten vorherzusagen. Ziel ist die Schaffung eines datengestÃ¼tzten Werkzeugs, das eine zustandsbasierte Instandhaltungsstrategie (Condition-Based Maintenance, CBM) anstelle von festen Wartungsintervallen ermÃ¶glicht.

## ğŸ“Š ProjektÃ¼bersicht

**Problemstellung:**
Die traditionelle Instandhaltung kritischer Maschinen wie Schiffsantriebe basiert hÃ¤ufig auf festen, zeitbasierten PlÃ¤nen. Dieser Ansatz kann ineffizient und riskant sein: Komponenten werden mÃ¶glicherweise vorzeitig ausgetauscht, obwohl sie sich noch in gutem Zustand befinden, oder sie fallen unerwartet vor der geplanten Wartung aus. Dies fÃ¼hrt zu kostspieligen Ausfallzeiten und potenziellen Sicherheitsrisiken. Das Kernproblem ist der fehlende Echtzeit-Einblick in den tatsÃ¤chlichen Gesundheitszustand und die Degradation der Systemkomponenten.

**Ziel:**
Das Hauptziel dieses Projekts ist die Entwicklung eines Machine-Learning-Modells, das den Grad des VerschleiÃŸes von Gasturbine und Kompressor nur anhand von Echtzeit-Betriebssensordaten prÃ¤zise vorhersagen kann. Dies schafft eine datengestÃ¼tzte Grundlage fÃ¼r eine CBM.

Die Kernziele sind:

- **PrÃ¤diktive Modellierung:** Erstellung und Training von Regressionsmodellen zur Vorhersage des `GT Compressor decay state coefficient` und `GT Turbine decay state coefficient`.
- **Analyse der Feature Importance:** Identifizierung der Betriebsparameter (z.B. Temperaturen, DrÃ¼cke, Drehzahlen), die die wichtigsten Indikatoren fÃ¼r den KomponentenverschleiÃŸ sind.
- **ErmÃ¶glichung von CBM:** Bereitstellung eines Proof-of-Concept fÃ¼r ein System, das die Wartungsplanung auf Basis des tatsÃ¤chlichen Maschinenzustands anstelle eines festen Zeitplans ermÃ¶glicht.

**Methoden:**
Das Projekt folgt einem klassischen Data-Science-Workflow unter Verwendung von Python und Bibliotheken wie Pandas, NumPy, Matplotlib, Seaborn und Scikit-learn. Die Kernmethoden umfassen:

- **Explorative Datenanalyse (EDA)**
- **Training und Vergleich mehrerer Regressionsmodelle** (Lineare Regression, Random Forest, XGBoost)
- **Analyse der Merkmalswichtigkeit (Feature Importance)**, um ingenieurtechnische Einblicke zu gewinnen.

## ğŸ“Š Daten

Die fÃ¼r dieses Projekt verwendeten Daten stammen aus dem "Condition Based Maintenance of Naval Propulsion Plants"-Datensatz des UCI Machine Learning Repository.

- **Quelle:** [Link zum Datensatz auf UCI](https://archive.ics.uci.edu/dataset/316/condition+based+maintenance+of+naval+propulsion+plants)
- **Quelle:** [Link zum Datensatz auf Kaggle](https://www.kaggle.com/datasets/thedevastator/improving-naval-vessel-condition-through-machine)
- **Inhalt:** Der Datensatz besteht aus 11.934 Datenpunkten, die jeweils eine Momentaufnahme des Zustands der Antriebsanlage darstellen. Er enthÃ¤lt 16 kontinuierliche Sensormesswerte (Features) und 2 Zielvariablen, die die Zustandskoeffizienten fÃ¼r den VerschleiÃŸ von Gasturbine und Kompressor reprÃ¤sentieren.

## ğŸ¤– Arbeitsablauf (Workflow)

Das Projekt wurde in die folgenden Hauptphasen gegliedert:

1.  **Laden und erste Analyse der Daten:** Verstehen der Datenstruktur, ÃœberprÃ¼fung auf fehlende Werte und ein erster Ãœberblick Ã¼ber die Verteilungen der Features.
2.  **Explorative Datenanalyse (EDA):** Detaillierte Untersuchung der ZusammenhÃ¤nge zwischen Sensordaten und KomponentenverschleiÃŸ. Dies umfasste die Visualisierung von Korrelationen mittels einer Heatmap und das Plotten von SchlÃ¼sselmerkmalen gegen die Zielvariablen, um Trends zu erkennen.
3.  **Feature Engineering & Datenvorverarbeitung:** Die Daten wurden fÃ¼r die Modellierung vorbereitet, indem sie in Trainings- und TestdatensÃ¤tze aufgeteilt wurden. Eine Skalierung der Features wurde in Betracht gezogen, fÃ¼r die verwendeten baumbasierten Modelle jedoch als nicht notwendig erachtet.
4.  **Modelltraining und -evaluierung:**
    - Es wurden zwei separate Modelle trainiert: eines fÃ¼r den Kompressor- und eines fÃ¼r den TurbinenverschleiÃŸ.
    - Verglichene Algorithmen: Lineare Regression (als Baseline), RandomForestRegressor und XGBoostRegressor.
    - Die Modelle wurden mit Metriken wie Mean Absolute Error (MAE), Root Mean Squared Error (RMSE) und dem BestimmtheitsmaÃŸ (RÂ²) bewertet.
5.  **Hyperparameter-Optimierung (Optional):** Das leistungsstÃ¤rkste Modell wurde mittels Techniken wie GridSearchCV weiter optimiert, um die optimalen Hyperparameter zu finden.

## Wichtigste Erkenntnisse & Ergebnisse

### Modellperformance

**(Noch anpassen, wenn Ergebnisse ready)**

Der XGBoost Regressor zeigte die beste Leistung bei der Vorhersage beider Zustandskoeffizienten. Das finale Modell erreichte die folgende Performance auf dem Testdatensatz:

| Komponente     | Zielvariable             | MAE      | RMSE     | RÂ² Score |
| -------------- | ------------------------ | -------- | -------- | -------- |
| **Kompressor** | `Compressor decay state` | `0.00XX` | `0.00XX` | `0.99XX` |
| **Turbine**    | `Turbine decay state`    | `0.00XX` | `0.00XX` | `0.99XX` |

### Feature Importance (Merkmalswichtigkeit)

Die Analyse zeigte, welche Sensormesswerte die entscheidendsten Indikatoren fÃ¼r den Zustand der Komponenten sind.

**(Hier noch Bilder zu Feature-Importance-Plots!)**

![Feature Importance Kompressor](images/compressor_importance.png)

Wichtige Erkenntnisse:

- FÃ¼r den **Kompressor** war `[Name des wichtigsten Features, z.B. Lufteintrittstemperatur]` der signifikanteste PrÃ¤diktor.
- FÃ¼r die **Turbine** hatte `[Name des wichtigsten Features, z.B. Turbineneintrittstemperatur]` den grÃ¶ÃŸten Einfluss auf die VerschleiÃŸvorhersage. Dies deckt sich mit ingenieurtechnischen Prinzipien, nach denen thermische Belastung ein Hauptfaktor fÃ¼r den TurbinenverschleiÃŸ ist.

## ğŸš€ Reproduzierbarkeit

### Setup

```bash
# Repository klonen
git clone https://github.com/IAmBlindNotDeaf/Gas-Turbine-Degradation-Prediction
cd Gas-Turbine-Degradation-Prediction

# Dependencies installieren
uv sync
```

### AusfÃ¼hrung

```bash
# Notebooks in dieser Reihenfolge ausfÃ¼hren:
# 1. notebooks/01_exploration.ipynb
# 2. notebooks/02_preprocessing.ipynb
# 3. notebooks/03_modeling.ipynb
# 4. notebooks/04_results.ipynb
```

## ğŸ“ Repository Struktur

```
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                    # Originaldaten
â”‚   â””â”€â”€ processed/              # Bereinigte Daten
â”œâ”€â”€ notebooks/                  # Jupyter Notebooks
â”‚   â””â”€â”€ 01_exploration.ipynb    # Datenexploration
â”œâ”€â”€ src/dpp                     # Python Module
â”œâ”€â”€ test/                       # Unit Tests
â”œâ”€â”€ pyproject.toml              # Projektkonfiguration
â””â”€â”€ docs/                       # ZusÃ¤tzliche Dokumentation
```

## ğŸ“ Ãœber dieses Projekt

**Kontext:**
Data Science Portfolio Porjekt

**Zeitraum:**
29.09.2025 - 17.10.2025

**Autor:**
Yunus Ahmet Sari

## ğŸ“ Kontakt

**GitHub:** [@IAmBlindNotDeaf](https://github.com/IAmBlindNotDeaf)  
**E-Mail:** yunus-sari@hotmail.de  
**LinkedIn:** [Mein Profil](https://www.linkedin.com/in/yunus-ahmet-sari-0670a7302/)

## ğŸ™ Danksagungen

---

**â­ Wenn dir dieses Projekt gefÃ¤llt, gib gerne einen Star!**
